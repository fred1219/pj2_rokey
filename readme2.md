# Face-Arm: AI 기반 협동 로봇 작업 어시스턴트

### 📅 프로젝트 개요

* **주제**: Face-Arm (서비스 협동 로봇)
* **목표**: 고령화 사회의 인력 부족 문제를 해결하기 위한 서비스 로봇 구현
* **팀원**: 4명

---

## 1. 개발 배경 및 기획

현재 한국은 고령사회에 진입했으며 초고령화 사회로의 전환을 앞두고 있습니다. 이에 따라 외국인 간병인 도입, 국민연금제도 개혁 등 다양한 노인복지 서비스와 정책이 제시되고 있지만, 여전히 뚜렷한 해결책을 찾지 못하고 있는 상황입니다. 이러한 문제는 사회 전반의 노인복지 부담을 가중시키는 요인으로 작용합니다.

본 프로젝트는 이러한 사회적 문제를 기술적으로 해결하기 위한 시도로, **노인복지 인력 및 인건비 부담을 줄이기 위한 서비스 협동 로봇**을 개발하고자 기획되었습니다.

### 핵심 기능

1. 음성 명령 인식 및 로봇 동작 트리거
2. 사용자 및 물체의 위치 인식
3. 로봇이 물체를 집어 사용자에게 전달

---

## 2. 주요 기능 구현 과정

### 2-1. 🎤 음성 명령 인식 (STT 기반 로봇 제어 트리거)

* **기술 스택 및 구조**

  * STT 엔진: OpenAI API
  * Wake-up Word 엔진: Whisper
  * 기타: 프롬프트 규칙 설계, 리소스 최적화

* **구현 내용**

  * Wake-up Word → STT → 명령어 추출 구조로 구현
  * 초기에는 STT가 상시 대기하는 구조였지만, 리소스 효율성 향상을 위해 wake-up 키워드(“Hello Rokey”) 인식 후 시작되는 구조로 감소
  * 명령에 따른 모든 동작은 시스템에서 유지적으로 처리

---

### 2-2. 📷 사용자 및 물체 위치 인식

* **기술 스택 및 구조**

  * 사용 감지 카메라: Logitech C270 (RGB)
  * 물체 인식 카메라: RealSense D435i (RGB-D)
  * 객체 인식: YOLO (ultralytics)
  * 캐리브레이션: OpenCV `cv2.calibrateHandEye()`
  * 자포 변환: numpy, Hand-Eye 검증 결과 파일(T\_gripper2camera.npy)

* **구현 내용**

  * RealSense D435i가 물체의 3D 위치 (x, y, z) 정보 가져옴
  * 카메라를 로벏팔에 붙인 Eye-in-Hand 구조에서 Hand-Eye Calibration 수행
  * Checkerboard 이미지 바퀴 차원과 OpenCV API에서 검증 수행
  * 사용자의 여명 및 위치는 Logitech C270 RGB 카메라를 통해 YOLO가 감지
  * 카메라 화면 자포계를 협동로벏 원경 자포계(
    x, z) 변환

    * 시스템의 물리적 동작 범위를 체치해 하드코딩한 값 (X: 50~~660mm, Z: 330~~630mm)으로 변환
    * 화면 해상도, 축 방향, 좌표계 차이 등을 반영

---

### 2-3. ⚖️ 로벏 동작 제어 및 물체 전달

* **기술 스택 및 구조**

  * ROS 2 기반 서비스 통신 (`/get_3d_position`, `/get_keyword`)
  * 로봇 제어: DSR\_ROBOT2 라이브러리 (`movej`, `movel`, `get_tool_force` 등)
  * 그리퍼 제어: OnRobot RG2 + 센서 상태 확인 (`get_status()` 사용)
  * 음성 안내: pydub (mp3 재생), Naver Clova TTS (더빙)

* **구현 내용**

  * YOLO가 감지한 물체 중심 좌표 → /get\_3d\_position 서비스 호출로 3D 좌표화
  * 변환 행렬 `T_gripper2camera.npy`와 현재 로봇 위치를 활용해 카메라 좌표 → 로봇 좌표로 변환
  * 물체 이동, Pick & Place는 `movej`, `movel`, RG2 구플에서 수행
  * 직접 구현한 `check_grip()` 함수로 그리퍼에 가해지는 외력을 읽어 물체 접촉 여부 판단

    * `OnRobot.get_status()`와 `get_tool_force()`를 활용
    * 외력 변화가 감지되면 그리퍼 동작 (닫기/열기) 및 음성(mp3) 안내 수행

---

## 3. 편보 과정 & 현황 처리

> (작성 예정)

---

## 4. 협업 내용 & 직체 진행

각 팀원은 주어진 파트를 주도적으로 맡아 개발했지만, 모든 기능은 유기적으로 연결되어 있어 팀원 간의 긴밀한 협력이 필수적이었습니다. 예를 들어, 위치 인식을 담당한 팀원은 음성 인식 시스템과의 통합을 고려해 데이터 흐름을 조율했고, 저는 음성 인식 파트를 담당하며 다른 기능과 원활하게 연동될 수 있도록 STT 트리거 설계를 진행했습니다. 또한, 이해도 차이가 있는 부분에 대해선 문서화 및 공유를 통해 팀 전체의 역량을 끌어올렸습니다.

---

## 5. 성과 및 결과물

> (작성 예정)

## 6. 결과: 목표 및 성과

> (작성 예정)

## 7. 프로젝트 화면 & 기능 데모

![image](https://github.com/user-attachments/assets/2b0b3f95-ca7c-4aef-9a30-81f8efa3dd3e)

## 8. 후기 및 행후 개선 사항

> (작성 예정)

## 9. 개인적 성찰 & 배우고 감독한 점

> (작성 예정)

## 10. 개선 및 확장 아이디어

> (작성 예정)
